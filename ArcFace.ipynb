{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Import Necessary Liberaries**"
      ],
      "metadata": {
        "id": "vAFG_GZTt8oB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UpM8yw6We9Zt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import math\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import Linear, Conv2d, BatchNorm1d, BatchNorm2d, PReLU, ReLU, Sigmoid, Dropout2d, Dropout, AvgPool2d, MaxPool2d, AdaptiveAvgPool2d, Sequential, Module, Parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Create Custom DataSet Class**"
      ],
      "metadata": {
        "id": "Z5VFycuDuENo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = Image.open(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "A4B1-WGWe-xZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Transform**"
      ],
      "metadata": {
        "id": "rWTUaEjJuLdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((112, 112)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "34PERfNDgnwg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Paths to the dataset and labels**"
      ],
      "metadata": {
        "id": "vVwrcZomuRbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(annotations_file='/content/drive/MyDrive/DL/data/dataset_labels.csv', img_dir='/content/drive/MyDrive/DL/data/new_dataset', transform=transform)"
      ],
      "metadata": {
        "id": "EC_PqVhGfEOA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train,Test, and Validation Split**"
      ],
      "metadata": {
        "id": "Fi170p0cuVpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_split = int(len(dataset) * 0.9)\n",
        "test_split = len(dataset) - train_val_split\n",
        "train_val_dataset, test_dataset = random_split(dataset, [train_val_split, test_split])"
      ],
      "metadata": {
        "id": "vw29gZm-fP8d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_split = int(train_val_split * 0.88)\n",
        "val_split = train_val_split - train_split\n",
        "train_dataset, val_dataset = random_split(train_val_dataset, [train_split, val_split])"
      ],
      "metadata": {
        "id": "qBusK5yqf0vw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Define Data Loaders for traun,test and validation dataset**"
      ],
      "metadata": {
        "id": "0dU14UdyugaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "nvnbovDWf3DF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Define Model**"
      ],
      "metadata": {
        "id": "pdIyeGBCu5CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Arcface(nn.Module):\n",
        "    def __init__(self, embedding_size=512, classnum=10,  s=64., m=0.5):\n",
        "        super(Arcface, self).__init__()\n",
        "        self.classnum = classnum\n",
        "        self.kernel = Parameter(torch.Tensor(embedding_size,classnum))\n",
        "        self.kernel.data.uniform_(-1, 1).renorm_(2,1,1e-5).mul_(1e5)\n",
        "        self.m = m\n",
        "        self.s = s\n",
        "        self.cos_m = math.cos(m)\n",
        "        self.sin_m = math.sin(m)\n",
        "        self.mm = self.sin_m * m\n",
        "        self.threshold = math.cos(math.pi - m)\n",
        "    def forward(self, embbedings, label):\n",
        "        nB = len(embbedings)\n",
        "        kernel_norm = l2_norm(self.kernel, axis=0)\n",
        "        cos_theta = torch.mm(embbedings, kernel_norm)\n",
        "        cos_theta = cos_theta.clamp(-1,1)\n",
        "        cos_theta_2 = torch.pow(cos_theta, 2)\n",
        "        sin_theta_2 = 1 - cos_theta_2\n",
        "        sin_theta = torch.sqrt(sin_theta_2)\n",
        "        cos_theta_m = (cos_theta * self.cos_m - sin_theta * self.sin_m)\n",
        "        cond_v = cos_theta - self.threshold\n",
        "        cond_mask = cond_v <= 0\n",
        "        keep_val = (cos_theta - self.mm)\n",
        "        cos_theta_m[cond_mask] = keep_val[cond_mask]\n",
        "        output = cos_theta * 1.0\n",
        "        idx_ = torch.arange(0, nB, dtype=torch.long)\n",
        "        output[idx_, label] = cos_theta_m[idx_, label]\n",
        "        output *= self.s\n",
        "        return output"
      ],
      "metadata": {
        "id": "YUW2c79jf54G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import Linear, Conv2d, BatchNorm1d, BatchNorm2d, PReLU, ReLU, Sigmoid, Dropout2d, Dropout, AvgPool2d, MaxPool2d, AdaptiveAvgPool2d, Sequential, Module, Parameter"
      ],
      "metadata": {
        "id": "vrpVJu8bf9E7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomArcfaceModel(nn.Module):\n",
        "    def __init__(self, num_classes, embedding_size, s, m, feature_extractor):\n",
        "        super(CustomArcfaceModel, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.embedding_size = embedding_size\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.arcface = Arcface(embedding_size, num_classes, s, m)\n",
        "        self.linear = nn.Linear(1024, embedding_size, bias=False)\n",
        "\n",
        "    def forward(self, x, labels):\n",
        "        embeddings = self.feature_extractor(x)\n",
        "        logits = self.arcface(embeddings, labels)\n",
        "        return logits\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KW-dRKmmf_d_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv_block(nn.Module):\n",
        "    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n",
        "        super(Conv_block, self).__init__()\n",
        "        self.conv = Conv2d(in_c, out_channels=out_c, kernel_size=kernel, groups=groups, stride=stride, padding=padding, bias=False)\n",
        "        self.bn = BatchNorm2d(out_c)\n",
        "        self.prelu = PReLU(out_c)\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.prelu(x)\n",
        "        return x\n",
        "\n",
        "class Linear_block(nn.Module):\n",
        "    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n",
        "        super(Linear_block, self).__init__()\n",
        "        self.conv = Conv2d(in_c, out_channels=out_c, kernel_size=kernel, groups=groups, stride=stride, padding=padding, bias=False)\n",
        "        self.bn = BatchNorm2d(out_c)\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "class Depth_Wise(nn.Module):\n",
        "     def __init__(self, in_c, out_c, residual = False, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=1):\n",
        "        super(Depth_Wise, self).__init__()\n",
        "        self.conv = Conv_block(in_c, out_c=groups, kernel=(1, 1), padding=(0, 0), stride=(1, 1))\n",
        "        self.conv_dw = Conv_block(groups, groups, groups=groups, kernel=kernel, padding=padding, stride=stride)\n",
        "        self.project = Linear_block(groups, out_c, kernel=(1, 1), padding=(0, 0), stride=(1, 1))\n",
        "        self.residual = residual\n",
        "     def forward(self, x):\n",
        "        if self.residual:\n",
        "            short_cut = x\n",
        "        x = self.conv(x)\n",
        "        x = self.conv_dw(x)\n",
        "        x = self.project(x)\n",
        "        if self.residual:\n",
        "            output = short_cut + x\n",
        "        else:\n",
        "            output = x\n",
        "        return output\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, c, num_block, groups, kernel=(3, 3), stride=(1, 1), padding=(1, 1)):\n",
        "        super(Residual, self).__init__()\n",
        "        modules = []\n",
        "        for _ in range(num_block):\n",
        "            modules.append(Depth_Wise(c, c, residual=True, kernel=kernel, padding=padding, stride=stride, groups=groups))\n",
        "        self.model = Sequential(*modules)\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "metadata": {
        "id": "2c6-g0AXgA8W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MobileFaceNet for feature extraction**"
      ],
      "metadata": {
        "id": "lpISTy_Bvkpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MobileFaceNet(nn.Module):\n",
        "    def __init__(self, embedding_size):\n",
        "        super(MobileFaceNet, self).__init__()\n",
        "        self.conv1 = Conv_block(3, 64, kernel=(3, 3), stride=(2, 2), padding=(1, 1))\n",
        "        self.conv2_dw = Conv_block(64, 64, kernel=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
        "        self.conv_23 = Depth_Wise(64, 64, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
        "        self.conv_3 = Residual(64, num_block=4, groups=128, kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv_34 = Depth_Wise(64, 128, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
        "        self.conv_4 = Residual(128, num_block=6, groups=256, kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv_45 = Depth_Wise(128, 128, kernel=(3, 3), stride=(2, 2), padding=(1, 1), groups=512)\n",
        "        self.conv_5 = Residual(128, num_block=2, groups=256, kernel=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "        self.conv_6_sep = Conv_block(128, 512, kernel=(1, 1), stride=(1, 1), padding=(0, 0))\n",
        "        self.conv_6_dw = Linear_block(512, 512, groups=512, kernel=(7,7), stride=(1, 1), padding=(0, 0))\n",
        "        self.conv_6_flatten = Flatten()\n",
        "        self.linear = Linear(512, embedding_size, bias=False)\n",
        "        self.bn = BatchNorm1d(embedding_size)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "\n",
        "        out = self.conv2_dw(out)\n",
        "\n",
        "        out = self.conv_23(out)\n",
        "\n",
        "        out = self.conv_3(out)\n",
        "\n",
        "        out = self.conv_34(out)\n",
        "\n",
        "        out = self.conv_4(out)\n",
        "\n",
        "        out = self.conv_45(out)\n",
        "\n",
        "        out = self.conv_5(out)\n",
        "\n",
        "        out = self.conv_6_sep(out)\n",
        "\n",
        "        out = self.conv_6_dw(out)\n",
        "\n",
        "        out = self.conv_6_flatten(out)\n",
        "\n",
        "        out = self.linear(out)\n",
        "\n",
        "        out = self.bn(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "GtaTCFrqgCSH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "def l2_norm(input,axis=1):\n",
        "    norm = torch.norm(input,2,axis,True)\n",
        "    output = torch.div(input, norm)\n",
        "    return output"
      ],
      "metadata": {
        "id": "-pxhQxoFgDsq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "embedding_size = 512\n",
        "s = 64.0\n",
        "m = 0.5\n"
      ],
      "metadata": {
        "id": "k5b9O_qOgFXa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Create Feature Extractor**"
      ],
      "metadata": {
        "id": "i4EIK4bCv1Hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = MobileFaceNet(embedding_size=512)"
      ],
      "metadata": {
        "id": "8dG4vfvbgHGq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Create Model**"
      ],
      "metadata": {
        "id": "vig0CEQmv7DV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arcface_model = Arcface(embedding_size, num_classes, s, m)"
      ],
      "metadata": {
        "id": "jHW6H_uLgKNT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomArcfaceModel(num_classes, embedding_size, s, m, feature_extractor)\n"
      ],
      "metadata": {
        "id": "g74RZsLbgLoI"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Define loss function**"
      ],
      "metadata": {
        "id": "P0pgmwwOwAAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "b9vlD377gNDn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Define optimizer**"
      ],
      "metadata": {
        "id": "ZgDEWBxKwMDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.95)"
      ],
      "metadata": {
        "id": "JNp1OGX4gfgj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_features = model.linear.in_features\n",
        "new_linear_layer = nn.Linear(in_features, num_classes)\n",
        "model.linear = new_linear_layer\n"
      ],
      "metadata": {
        "id": "Hu6VaegdmVO4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_bn_layer = nn.BatchNorm1d(num_classes)\n",
        "model.bn = new_bn_layer"
      ],
      "metadata": {
        "id": "eW3_JLp-mzWl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training Loop**"
      ],
      "metadata": {
        "id": "3nzw_6BawQkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50"
      ],
      "metadata": {
        "id": "Utpe9X5VgPOO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.io import read_image"
      ],
      "metadata": {
        "id": "1Eij_x-NgQ8_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs,labels)\n",
        "       # print(outputs)\n",
        "        #print(labels)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    # Print training statistics\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, '\n",
        "          f'Training Loss: {total_loss / len(train_loader):.4f}, '\n",
        "          f'Training Accuracy: {(100 * correct / total):.2f}%')\n"
      ],
      "metadata": {
        "id": "mFUb-UV2j6_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on the test dataset\n",
        "model.eval()\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        logits = model(inputs, labels)\n",
        "        _, predicted = torch.max(logits, 1)\n",
        "        total_samples += labels.size(0)\n",
        "        total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = total_correct / total_samples\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "id": "OPfYEvrttMl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/DL/ArcFaceModel.pth')\n",
        "print(\"Model Saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IjCtwkJ_jR9",
        "outputId": "e0aaf4dd-0a27-4d95-afb7-0fa281965700"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lAQa6eW5_qwv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}